Literature_DL4TemporalData
**************************************
A paper list about representation learning of temporal data (including multivariate time series, event sequences, and heterogeneous temporal event data). These works could be applied to learn the representations of temporal data for predicitons, in the domains such as healthcare.

.. contents::
    :local:
    :depth: 2

.. sectnum::
    :depth: 2

.. role:: author(emphasis)

.. role:: venue(strong)

.. role:: keyword(emphasis)



Advanced Models for Long Sequences 
===========================

RNN-based Models
-----------------------------------------

`Phased lstm: Accelerating recurrent network training for long or event-based sequences
<https://papers.nips.cc/paper/6310-phased-lstm-accelerating-recurrent-network-training-for-long-or-event-based-sequences.pdf>`_
    | :author:`Neil Daniel, Pfeiffer Michael, Liu Shih-Chii`
    | :venue:`NIPS 2016`
    | :keyword:`Long event-based sequences, Asychronized sparse asynchronous streams, Sparse updating`
    
`Learning the joint representation of heterogeneous temporal events for clinical endpoint prediction
<https://arxiv.org/abs/1803.04837>`_
    | :author:`Liu Luchen, Shen Jianhao, Zhang Ming, Wang Zichang, Tang Jian`
    | :venue:`AAAI 2018`
    | :keyword:`Endpoint prediciton, Sequential Data Modeling, Electronic Health Record`
    
`Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks
<https://arxiv.org/abs/1803.04837>`_
    | :author:`Yikang Shen, Shawn Tan, Alessandro Sordoni, Aaron Courville`
    | :venue:`ICLR 2019 (best paper)`
    | :keyword:`NLP, Hidden hierarchically structured, Ordered neurons`
    
 
 Herachical ICLR19

CNN-based Models
-----------------------------------------

CNN

TCN
 
Attention-based Models
-----------------------------------------

Transformer

SanD

XL-Transformer

Sequence with Latent Graphs
============================

NRI

GCT


